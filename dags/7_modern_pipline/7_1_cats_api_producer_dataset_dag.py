"""DAG A (Dataset): cats_api_producer_dataset_dag

Ğ¢Ğ¾ Ğ¶Ğµ ÑĞ°Ğ¼Ğ¾Ğµ, Ñ‡Ñ‚Ğ¾ cats_api_producer_dag, Ğ½Ğ¾ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ TriggerDagRun Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Airflow Datasets.

Producer:
- Ğ—Ğ°Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ N ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ñ… Ñ„Ğ¾Ñ‚Ğ¾ ĞºĞ¾Ñ‚Ğ¾Ğ² (metadata) Ğ¸Ğ· TheCatAPI
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ raw JSON Ğ² MinIO
- ĞŸÑƒĞ±Ğ»Ğ¸ĞºÑƒĞµÑ‚ Dataset ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğµ Ñ extra (bucket/key)

Consumer DAG Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° ÑÑ‚Ğ¾Ñ‚ Dataset.

Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº:
GET https://api.thecatapi.com/v1/images/search
"""

from __future__ import annotations

import json
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List

from airflow import DAG
from airflow.datasets import Dataset
from airflow.decorators import task
from airflow.models import Variable
from airflow.providers.amazon.aws.hooks.s3 import S3Hook
from airflow.providers.http.sensors.http import HttpSensor
from airflow.providers.http.hooks.http import HttpHook


CAT_API_ENDPOINT = "/v1/images/search"
THECATAPI_CONN_ID = Variable.get("THECATAPI_CONN_ID", default_var="thecatapi_default")
MINIO_CONN_ID = Variable.get("MINIO_CONN_ID", default_var="minio")
RAW_BUCKET = Variable.get("MINIO_BUCKET_CATS", default_var="cats")
RAW_PREFIX = Variable.get("MINIO_RAW_PREFIX", default_var="raw")

CATS_RAW_DATASET = Dataset(f"minio://{RAW_BUCKET}/{RAW_PREFIX}")


default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "start_date": datetime(2024, 1, 1),
    "retries": 1,
    "retry_delay": timedelta(minutes=3),
}


dag = DAG(
    dag_id="7_1_cats_api_producer_dataset_dag",
    default_args=default_args,
    description="Producer (Dataset): fetch N cats -> save raw to MinIO -> publish Dataset event",
    schedule_interval=None,
    catchup=False,
    tags=["cats", "api", "minio", "dataset", "producer", "basic_pipeline"],
)


check_cat_api = HttpSensor(
    task_id="check_cat_api",
    http_conn_id=THECATAPI_CONN_ID,
    endpoint=CAT_API_ENDPOINT,
    request_params={"limit": 1},
    response_check=lambda r: r.status_code == 200,
    poke_interval=20,
    timeout=120,
    mode="reschedule",
    dag=dag,
)


@task(task_id="fetch_cats", dag=dag)
def fetch_cats(n: int = 10) -> Dict[str, Any]:
    hook = HttpHook(method="GET", http_conn_id=THECATAPI_CONN_ID)

    items: List[Dict[str, Any]] = []
    for _ in range(int(n)):
        r = hook.run(CAT_API_ENDPOINT)
        r.raise_for_status()
        payload = r.json()
        if not isinstance(payload, list) or not payload:
            raise ValueError(f"Unexpected payload: {payload}")
        items.append(payload[0])

    return {
        "n": int(n),
        "fetched_at": datetime.now(timezone.utc).isoformat(),
        "items": items,
    }


@task(outlets=[CATS_RAW_DATASET])
def save_raw_to_minio(raw: Dict[str, Any]):
    """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ raw JSON Ğ² MinIO Ğ¸ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºÑƒĞµÑ‚ Dataset ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğµ.

    Dataset Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ ĞºĞ°Ğº Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ»: "Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹ Ğ² bucket/prefix".
    Consumer DAG Ğ·Ğ½Ğ°ĞµÑ‚ ÑĞ¾Ğ³Ğ»Ğ°ÑˆĞµĞ½Ğ¸Ğµ (bucket=cats, prefix=raw/) Ğ¸ ÑĞ°Ğ¼ Ğ½Ğ°Ğ¹Ğ´Ñ‘Ñ‚ Ğ½ÑƒĞ¶Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ».
    """

    s3 = S3Hook(aws_conn_id=MINIO_CONN_ID)
    if not s3.check_for_bucket(RAW_BUCKET):
        s3.create_bucket(bucket_name=RAW_BUCKET)

    ts = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
    key = f"{RAW_PREFIX}/cats_raw_{ts}.json"

    body = json.dumps(raw, ensure_ascii=False).encode("utf-8")
    s3.load_bytes(bytes_data=body, key=key, bucket_name=RAW_BUCKET, replace=True)

    print(f"âœ… Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½ Ñ„Ğ°Ğ¹Ğ»: s3://{RAW_BUCKET}/{key}")
    print(f"ğŸ“¢ ĞŸÑƒĞ±Ğ»Ğ¸ĞºÑƒĞµÑ‚ÑÑ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğµ Dataset: {CATS_RAW_DATASET.uri}")


raw = fetch_cats()
ref = save_raw_to_minio(raw)

check_cat_api >> raw >> ref
